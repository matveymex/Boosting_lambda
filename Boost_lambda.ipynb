{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbfa50ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import numpy as np\n",
    "import torch\n",
    "from catboost.datasets import msrank_10k\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self, n_estimators: int = 100, lr: float = 0.5, ndcg_top_k: int = 10,\n",
    "                 subsample: float = 0.9, colsample_bytree: float = 0.9,\n",
    "                 max_depth: int = 5, min_samples_leaf: int = 8):\n",
    "        self._prepare_data()\n",
    "\n",
    "        self.ndcg_top_k = ndcg_top_k\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = lr\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.subsample = subsample\n",
    "        self.colsample_bytree = colsample_bytree\n",
    "        self.trees = []\n",
    "        self.indices = []\n",
    "\n",
    "\n",
    "    def _get_data(self) -> List[np.ndarray]:\n",
    "        train_df, test_df = msrank_10k()\n",
    "\n",
    "        X_train = train_df.drop([0, 1], axis=1).values\n",
    "        y_train = train_df[0].values\n",
    "        query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "        X_test = test_df.drop([0, 1], axis=1).values\n",
    "        y_test = test_df[0].values\n",
    "        query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        (X_train, y_train, self.query_ids_train,\n",
    "            X_test, y_test, self.query_ids_test) = self._get_data()\n",
    "        \n",
    "        X_train = self._scale_features_in_query_groups(X_train,self.query_ids_train)\n",
    "        X_test = self._scale_features_in_query_groups(X_test,self.query_ids_test)\n",
    "        self.X_train = torch.FloatTensor(X_train)\n",
    "        self.X_test = torch.FloatTensor(X_test)\n",
    "        self.ys_train = torch.reshape(torch.FloatTensor(y_train),(len(y_train), 1))\n",
    "        self.ys_test = torch.reshape(torch.FloatTensor(y_test),(len(y_test), 1))\n",
    "        pass\n",
    "\n",
    "    def _scale_features_in_query_groups(self, inp_feat_array: np.ndarray,\n",
    "                                        inp_query_ids: np.ndarray) -> np.ndarray:\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        y_ids = inp_query_ids\n",
    "        inp_f = inp_feat_array\n",
    "        \n",
    "        y_uniques = np.unique(y_ids)\n",
    "        \n",
    "        for i,yi in enumerate(y_uniques):\n",
    "            scaler = StandardScaler()\n",
    "            inp_i = scaler.fit_transform(inp_f[y_ids == yi])\n",
    "\n",
    "            if i == 0:\n",
    "                \n",
    "                inp_all = inp_i\n",
    "            else:\n",
    "                inp_all = np.append(inp_all,inp_i,axis = 0)  \n",
    "\n",
    "        return inp_all\n",
    "\n",
    "    def _train_one_tree(self, cur_tree_idx: int,\n",
    "                        train_preds: torch.FloatTensor\n",
    "                        ,param) -> Tuple[DecisionTreeRegressor, np.ndarray]:\n",
    "        np.random.seed(cur_tree_idx)\n",
    "        new_lambdas = torch.zeros(train_preds.size())\n",
    "        for i , cur_id in enumerate(np.unique(self.query_ids_train)) :\n",
    "            mask_train = self.query_ids_train == cur_id\n",
    "            new_lambdas[mask_train] = self._compute_lambdas(self.ys_train[mask_train] ,\n",
    "                                                            train_preds[mask_train])\n",
    "\n",
    "        idx_col = np.random.choice(self.X_train.size(1) , int(self.X_train.size(1) * self.colsample_bytree))\n",
    "        idx_sub = np.random.choice(train_preds.size(0) , int(train_preds.size(0) * self.subsample))\n",
    "        parameter = { \"splitter\" : \"best\" ,\n",
    "                      \"max_depth\" : self.max_depth ,\n",
    "                      \"min_samples_leaf\" : self.min_samples_leaf ,\n",
    "                      \"min_weight_fraction_leaf\" : 0.4 ,\n",
    "                      \"max_leaf_nodes\" : 9 }\n",
    "        \n",
    "        model = DecisionTreeRegressor(**param)\n",
    "        model.fit(self.X_train[idx_sub][: , idx_col] , torch.reshape(torch.flatten(new_lambdas)[idx_sub] , (-1 , 1)))\n",
    "        return model , idx_col\n",
    "\n",
    "    def _calc_data_ndcg(self, queries_list: np.ndarray,\n",
    "                        true_labels: torch.FloatTensor, preds: torch.FloatTensor) -> float:\n",
    "        ndcg_s = []\n",
    "        for i,cur_id in enumerate(np.unique(queries_list)):\n",
    "            mask_train = queries_list == cur_id\n",
    "            cur_ndcg = self._ndcg_k(true_labels[mask_train],\n",
    "                                                       preds[mask_train],self.ndcg_top_k) \n",
    "            if np.isnan(cur_ndcg):\n",
    "                ndcg_s.append(0)\n",
    "                continue\n",
    "                \n",
    "            ndcg_s.append(cur_ndcg) \n",
    "        return np.mean(ndcg_s)\n",
    "\n",
    "    def fit(self):\n",
    "        np.random.seed(0)\n",
    "\n",
    "        space4dt = {\n",
    "\n",
    "            'max_depth': hp.choice('max_depth', range(2,90)),\n",
    "            \"max_leaf_nodes\":hp.choice(\"max_leaf_nodes\",range(10,90)),\n",
    "            \"min_samples_split\":hp.choice(\"min_samples_split\",range(10,90)),\n",
    "            \"min_samples_leaf\":hp.choice(\"min_samples_leaf\",range(10,90)), \n",
    "            \"min_weight_fraction_leaf\" : hp.choice(\"min_weight_fraction_leaf\",[0.012]),\n",
    "            \"random_state\" : hp.choice(\"random_state\",[14,20,150])                      \n",
    "        }    \n",
    "        def f(params):     \n",
    "            y_pred_train = torch.zeros(self.ys_train.size())\n",
    "            y_pred_test = torch.zeros(self.ys_test.size())\n",
    "            models = []\n",
    "            indices_all = []\n",
    "\n",
    "            ndcg_best = 0\n",
    "            best_tree = 0\n",
    "                \n",
    "            for tree in range(self.n_estimators):\n",
    "                model, indices = self._train_one_tree(tree , y_pred_train, params)\n",
    "                models.append(model)\n",
    "                indices_all.append(indices)\n",
    "                self.trees = models\n",
    "                self.indices = indices_all\n",
    "\n",
    "                y_pred_temp_train = torch.Tensor(model.predict(self.X_train[: , indices]))\n",
    "                y_pred_temp_test = torch.Tensor(model.predict(self.X_test[: , indices]))\n",
    "\n",
    "                y_pred_temp_train = torch.reshape(y_pred_temp_train , y_pred_train.size())\n",
    "                y_pred_temp_test = torch.reshape(y_pred_temp_test , y_pred_test.size())\n",
    "\n",
    "                y_pred_train -= self.lr * y_pred_temp_train \n",
    "                y_pred_test -= self.lr * y_pred_temp_test \n",
    "\n",
    "                ndcg_test = self._calc_data_ndcg(self.query_ids_test ,\n",
    "                                                torch.flatten(self.ys_test) , torch.flatten(y_pred_test))\n",
    "                ndcg_train = self._calc_data_ndcg(self.query_ids_train ,\n",
    "                                                torch.flatten(self.ys_train) , torch.flatten(y_pred_train))\n",
    "#                 print(f\"размер выборок test:{y_pred_test.size()}  train: {y_pred_train.size()}\")\n",
    "                preds_test = self.predict(self.X_test)\n",
    "#                 print('Test NDCG из predict:', self._calc_data_ndcg(self.query_ids_test, \n",
    "#                                                          torch.flatten(self.ys_test), torch.flatten(preds_test)))\n",
    "                if tree % 50 == 0: \n",
    "                    print(f\"tree_num:{tree}, test: {ndcg_test}, train:{ndcg_train}\" )\n",
    "                if ndcg_test > ndcg_best :\n",
    "                    ndcg_best = ndcg_test\n",
    "                    best_tree = tree\n",
    "                if tree == 99:\n",
    "                    print(model.get_params())\n",
    "                \n",
    "            return {'loss': 1 - ndcg_best, 'status': STATUS_OK} \n",
    "        \n",
    "        trials = Trials()\n",
    "        best = fmin(f, space4dt, algo=tpe.suggest, max_evals=15, trials=trials)\n",
    "        print ('best:', best)\n",
    "        print(best)\n",
    "        self.trials = trials\n",
    "        \n",
    "        \n",
    "        # Best model\n",
    "        y_pred_train = torch.zeros(self.ys_train.size())\n",
    "        y_pred_test = torch.zeros(self.ys_test.size())\n",
    "        models = []\n",
    "        indices_all = []\n",
    "\n",
    "        ndcg_best = 0\n",
    "        best_tree = 0\n",
    "\n",
    "        for tree in range(self.n_estimators) :\n",
    "\n",
    "            model, indices = self._train_one_tree(tree , y_pred_train,best)\n",
    "\n",
    "            models.append(model)\n",
    "            indices_all.append(indices)\n",
    "            self.trees = models\n",
    "            self.indices = indices_all\n",
    "\n",
    "            y_pred_temp_train = torch.Tensor(model.predict(self.X_train[: , indices]))\n",
    "            y_pred_temp_test = torch.Tensor(model.predict(self.X_test[: , indices]))\n",
    "\n",
    "            y_pred_temp_train = torch.reshape(y_pred_temp_train , y_pred_train.size())\n",
    "            y_pred_temp_test = torch.reshape(y_pred_temp_test , y_pred_test.size())\n",
    "            \n",
    "            y_pred_train -= self.lr * y_pred_temp_train \n",
    "            y_pred_test -= self.lr * y_pred_temp_test \n",
    "            \n",
    "            ndcg_test = self._calc_data_ndcg(self.query_ids_test ,\n",
    "                                            torch.flatten(self.ys_test) , torch.flatten(y_pred_test))\n",
    "            ndcg_train = self._calc_data_ndcg(self.query_ids_train ,\n",
    "                                            torch.flatten(self.ys_train) , torch.flatten(y_pred_train))\n",
    "\n",
    "            preds_test = self.predict(self.X_test)\n",
    "#             print('Test NDCG из predict:', self._calc_data_ndcg(self.query_ids_test, \n",
    "#                                                      torch.flatten(self.ys_test), torch.flatten(preds_test)))\n",
    "            if tree % 50 == 0:             \n",
    "                print(f\"tree number:{tree}, test: {ndcg_test}, train:{ndcg_train}\" )\n",
    "            if ndcg_test > ndcg_best :\n",
    "                ndcg_best = ndcg_test\n",
    "                best_tree = tree\n",
    "\n",
    "        self.indices = indices_all[:best_tree+1] \n",
    "        self.best_ndcg = ndcg_best\n",
    "        self.trees = models[:best_tree+1]\n",
    "        \n",
    "        print(ndcg_best,best_tree)\n",
    "        \n",
    "        self.save_model(\"model.sav\")\n",
    "        pass\n",
    "\n",
    "    def predict(self, data: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \n",
    "#         self.load_model( \"model.sav\")\n",
    "        \n",
    "        y_pred_temp = torch.flatten(torch.zeros(self.ys_train.size())) # first forecast \n",
    "        for i in range(len(self.trees)):\n",
    "\n",
    "            tree_pred = torch.flatten(torch.Tensor(self.trees[i].predict(data[:,self.indices[i]]))) # tree forecast  \n",
    "            y_pred_temp -=self.lr*tree_pred # grad boost step \n",
    "            \n",
    "        return y_pred_temp  \n",
    "\n",
    "    def _compute_lambdas(self, y_true: torch.FloatTensor, y_pred: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        def compute_labels_in_batch(y_true):\n",
    "\n",
    "            # the difference of relevance of each with each object\n",
    "            rel_diff = y_true - y_true.t()\n",
    "\n",
    "            # 1 if more relevant\n",
    "            pos_pairs = (rel_diff > 0).type(torch.float32)\n",
    "\n",
    "            # 1 if less relevant\n",
    "            neg_pairs = (rel_diff < 0).type(torch.float32)\n",
    "            Sij = pos_pairs - neg_pairs\n",
    "            return Sij\n",
    "\n",
    "        def compute_gain_diff(y_true, gain_scheme):\n",
    "            if gain_scheme == \"exp2\":\n",
    "                gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.t())\n",
    "            elif gain_scheme == \"diff\":\n",
    "                gain_diff = y_true - y_true.t()\n",
    "            else:\n",
    "                raise ValueError(f\"{gain_scheme} method not supported\")\n",
    "            return gain_diff\n",
    "\n",
    "        def compute_gain(y_value: float, gain_scheme: str) -> float:\n",
    "            if gain_scheme == \"const\":\n",
    "                gain = y_value\n",
    "\n",
    "            if gain_scheme == \"exp2\":   \n",
    "                gain = 2**y_value-1\n",
    "\n",
    "            return gain\n",
    "        \n",
    "        def compute_ideal_dcg(ys_true: torch.Tensor, gain_scheme: str) -> float:\n",
    "            values_true , indices_true = torch.flatten(ys_true).sort(descending = True)\n",
    "            gain_id = 0\n",
    "            for i in range(len(values_true)):   \n",
    "                gain_id+= float(compute_gain(values_true[i].item(),gain_scheme)/math.log2(i+2))\n",
    "            return float(gain_id)\n",
    "        \n",
    "        ideal_dcg = compute_ideal_dcg(torch.flatten(y_true), gain_scheme=\"exp2\")\n",
    "\n",
    "        if ideal_dcg == 0:\n",
    "            N = 0\n",
    "        else: \n",
    "\n",
    "            N = 1 / ideal_dcg\n",
    "\n",
    "        # calculate the order of documents according to relevance estimates\n",
    "        _, rank_order = torch.sort(y_true, descending=True, axis=0)\n",
    "        rank_order += 1\n",
    "        ndcg_scheme= \"exp2\"\n",
    "        with torch.no_grad():\n",
    "            # we get all pairwise pressure differences in the butch\n",
    "            pos_pairs_score_diff = 1.0 + torch.exp((y_pred - y_pred.t()))\n",
    "\n",
    "            # we put the markup for pairs, 1 if the first document is more relevant\n",
    "            # -1 if the second document is more relevant\n",
    "            Sij = compute_labels_in_batch(y_true)\n",
    "            # calculate the gain change due to permutations\n",
    "            gain_diff = compute_gain_diff(y_true, ndcg_scheme)\n",
    "\n",
    "            # calculate the change in the denominators-discounters\n",
    "            decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - (1.0 / torch.log2(rank_order.t() + 1.0))\n",
    "            # calculate nDCG bies\n",
    "            delta_ndcg = torch.abs(N * gain_diff * decay_diff)\n",
    "            # calculate lambdas\n",
    "            lambda_update =  (0.5 * (1 - Sij) - 1 / pos_pairs_score_diff) * delta_ndcg\n",
    "            lambda_update = torch.sum(lambda_update, dim=1, keepdim=True)\n",
    "\n",
    "            return lambda_update\n",
    "\n",
    "\n",
    "    def _ndcg_k(self , ys_true , ys_pred , ndcg_top_k) -> float :\n",
    "\n",
    "        def compute_gain(y_value: float , gain_scheme: str) -> float :\n",
    "            if gain_scheme == \"const\" :\n",
    "                gain = y_value\n",
    "\n",
    "            if gain_scheme == \"exp2\" :\n",
    "                gain = 2 ** y_value - 1\n",
    "            return gain\n",
    "\n",
    "        def dcg(ys_true: torch.Tensor , ys_pred: torch.Tensor , gain_scheme: str , ndcg_top_k) -> float :\n",
    "            values_pred , indices_pred = ys_pred.sort(descending=True)\n",
    "            ys_true = ys_true[indices_pred]\n",
    "            gain = 0\n",
    "            for i in range(len(ys_true[:ndcg_top_k])) :\n",
    "                gain += float(compute_gain(ys_true[i].item() , gain_scheme) / math.log2(i + 2))\n",
    "            return float(gain)\n",
    "\n",
    "        gain = dcg(ys_true , ys_pred , \"exp2\" , ndcg_top_k)\n",
    "\n",
    "        gain_ideal = dcg(ys_true , ys_true , \"exp2\" , ndcg_top_k)\n",
    "\n",
    "        if gain_ideal == 0:\n",
    "            ndcg = 0\n",
    "        else:\n",
    "            ndcg = gain / gain_ideal\n",
    "        return ndcg     \n",
    "    \n",
    "    def save_model(self, path: str):\n",
    "        state = {\"trees\":self.trees,\n",
    "                \"indices\":self.indices,\n",
    "                \"lr\":self.lr}\n",
    "        f = open(path, 'wb')\n",
    "        pickle.dump(state, f)\n",
    "        pass\n",
    "\n",
    "            \n",
    "    def load_model(self, path: str):\n",
    "        all_model = pickle.load(open(path , 'rb'))\n",
    "        self.trees , self.indices , self.lr = all_model[\"trees\"] , all_model[\"indices\"] , all_model[\"lr\"]\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "962ef949",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_num:0, test: 0.37045285175485515, train:0.4112899819120048                 \n",
      "tree_num:50, test: 0.40517524409384703, train:0.6792054999217738                \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 55, 'max_features': None, 'max_leaf_nodes': 51, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 15, 'min_samples_split': 84, 'min_weight_fraction_leaf': 0.012, 'random_state': 20, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.37489140158732664, train:0.4126823294928434                 \n",
      "tree_num:50, test: 0.41655861587823767, train:0.6916886796083347                \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 26, 'max_features': None, 'max_leaf_nodes': 85, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 80, 'min_samples_split': 34, 'min_weight_fraction_leaf': 0.012, 'random_state': 150, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.37489140158732664, train:0.4126823294928434                 \n",
      "tree_num:50, test: 0.41655861587823767, train:0.6916886796083347                \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 26, 'max_features': None, 'max_leaf_nodes': 85, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 77, 'min_samples_split': 58, 'min_weight_fraction_leaf': 0.012, 'random_state': 150, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.37724156442415635, train:0.4211930038315143                 \n",
      "tree_num:50, test: 0.3991235389549136, train:0.6384724856608944                 \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 26, 'max_features': None, 'max_leaf_nodes': 25, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 84, 'min_samples_split': 65, 'min_weight_fraction_leaf': 0.012, 'random_state': 150, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.375715738950767, train:0.4203154100323188                   \n",
      "tree_num:50, test: 0.408434169467177, train:0.6316761014659198                  \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 72, 'max_features': None, 'max_leaf_nodes': 24, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 12, 'min_samples_split': 12, 'min_weight_fraction_leaf': 0.012, 'random_state': 150, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.37489140158732664, train:0.4126823294928434                 \n",
      "tree_num:50, test: 0.41837237493612295, train:0.6880641187304141                \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 58, 'max_features': None, 'max_leaf_nodes': 71, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 89, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.012, 'random_state': 14, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.3792896708859267, train:0.42325300936817                    \n",
      "tree_num:50, test: 0.41269321166483314, train:0.6286348553023341                \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 34, 'max_features': None, 'max_leaf_nodes': 23, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 57, 'min_samples_split': 55, 'min_weight_fraction_leaf': 0.012, 'random_state': 20, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.37660870532966617, train:0.39270755180984473                \n",
      "tree_num:50, test: 0.40319194480168524, train:0.5697435533546367                \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': 79, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 75, 'min_samples_split': 19, 'min_weight_fraction_leaf': 0.012, 'random_state': 20, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.37790160444658144, train:0.4205569546380742                 \n",
      "tree_num:50, test: 0.40298827080005495, train:0.6744062180262731                \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 25, 'max_features': None, 'max_leaf_nodes': 47, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 42, 'min_samples_split': 46, 'min_weight_fraction_leaf': 0.012, 'random_state': 14, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.37514587510431985, train:0.41283941672754226                \n",
      "tree_num:50, test: 0.4082258866517833, train:0.6899868732302699                 \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 17, 'max_features': None, 'max_leaf_nodes': 62, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 76, 'min_samples_split': 50, 'min_weight_fraction_leaf': 0.012, 'random_state': 150, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.384364271111895, train:0.4187369286596244                   \n",
      "tree_num:50, test: 0.4188536202992511, train:0.667501737386814                  \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 44, 'max_features': None, 'max_leaf_nodes': 39, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 51, 'min_samples_split': 82, 'min_weight_fraction_leaf': 0.012, 'random_state': 14, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.37298893975012637, train:0.4148829009262645                 \n",
      "tree_num:50, test: 0.4159813643457469, train:0.6907297263146787                 \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 40, 'max_features': None, 'max_leaf_nodes': 52, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 35, 'min_samples_split': 50, 'min_weight_fraction_leaf': 0.012, 'random_state': 14, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.37336170197489355, train:0.3979697441544683                 \n",
      "tree_num:50, test: 0.40691549771965185, train:0.5928685030143465                \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 6, 'max_features': None, 'max_leaf_nodes': 16, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 33, 'min_samples_split': 29, 'min_weight_fraction_leaf': 0.012, 'random_state': 14, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.37489140158732664, train:0.4126823294928434                 \n",
      "tree_num:50, test: 0.41655861587823767, train:0.6916886796083347                \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 31, 'max_features': None, 'max_leaf_nodes': 76, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 21, 'min_samples_split': 21, 'min_weight_fraction_leaf': 0.012, 'random_state': 150, 'splitter': 'best'}\n",
      "tree_num:0, test: 0.3889745064396892, train:0.4166885822319566                  \n",
      "tree_num:50, test: 0.4209775137616443, train:0.6762886231733474                 \n",
      "{'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 46, 'max_features': None, 'max_leaf_nodes': 42, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 66, 'min_samples_split': 20, 'min_weight_fraction_leaf': 0.012, 'random_state': 20, 'splitter': 'best'}\n",
      "100%|█████████| 15/15 [14:37<00:00, 58.52s/trial, best loss: 0.5680796742215035]\n",
      "best: {'max_depth': 42, 'max_leaf_nodes': 29, 'min_samples_leaf': 41, 'min_samples_split': 72, 'min_weight_fraction_leaf': 0, 'random_state': 0}\n",
      "{'max_depth': 42, 'max_leaf_nodes': 29, 'min_samples_leaf': 41, 'min_samples_split': 72, 'min_weight_fraction_leaf': 0, 'random_state': 0}\n",
      "tree number:0, test: 0.31548851191824456, train:0.4144623758885035\n",
      "tree number:50, test: 0.38898139108884755, train:0.6823824676468676\n",
      "0.40217029287949013 98\n"
     ]
    }
   ],
   "source": [
    "sol = Solution()\n",
    "sol.fit()\n",
    "# best_params = {'max_depth': 7, 'max_leaf_nodes': 17, 'min_samples_leaf': 16, 'min_samples_split': 11, 'min_weight_fraction_leaf': 0.012}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b8bba8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': 8,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': 21,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 19,\n",
       " 'min_samples_split': 6,\n",
       " 'min_weight_fraction_leaf': 0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.trees[0].get_params()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
